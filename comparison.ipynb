{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN8MSR1S0uZhrFwj6vMgheP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SaraElwatany/Lung-TumorDetection-Segmentation/blob/main/comparison.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "f1h22hs0Oic7"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import torch\n",
        "import shutil\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "from PIL import Image\n",
        "from google.colab import drive\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision.transforms as T\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import Dataset, DataLoader, random_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kjhIHHVlXyCR",
        "outputId": "8132b959-ae79-459b-a280-7dde5b9f837c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "i_zlPVxYX5Wf"
      },
      "outputs": [],
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sdWWrZNadOiV"
      },
      "source": [
        "#### **DataLoading & Splitting**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "E4-J0tPoYTEZ"
      },
      "outputs": [],
      "source": [
        "dataset_path = '/content/drive/MyDrive/LungTumorDetectionAndSegmentation'"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Validation on Whole Images**"
      ],
      "metadata": {
        "id": "ayGrAmJ7gI3T"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "5VJ0sUlQY9hh"
      },
      "outputs": [],
      "source": [
        "class LungTumorSegmentationDataset(Dataset):\n",
        "\n",
        "    def __init__(self, root_path, transform=None, mask_transform=None):\n",
        "\n",
        "        self.images = []\n",
        "        for subject in os.listdir(os.path.join(root_path, 'images')):\n",
        "            subject_path = os.path.join(root_path, 'images', subject)\n",
        "            for image_file in os.listdir(subject_path):\n",
        "                self.images.append(os.path.join(subject_path, image_file))\n",
        "\n",
        "        self.masks = [img_path.replace('images', 'masks') for img_path in self.images]\n",
        "        self.transform = transform\n",
        "        self.mask_transform = mask_transform\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "\n",
        "        image_path = self.images[idx]\n",
        "        mask_path = self.masks[idx]\n",
        "\n",
        "        image = Image.open(image_path).convert(\"L\")  # grayscale image\n",
        "        mask = Image.open(mask_path).convert(\"L\")    # mask as single-channel\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        if self.mask_transform:\n",
        "            mask = self.mask_transform(mask)\n",
        "            mask = (mask > 0.5).float()  # Ensure binary values\n",
        "\n",
        "        return image_path, image, mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "IgDRAQseciyk"
      },
      "outputs": [],
      "source": [
        "image_transform = T.Compose([\n",
        "                              T.Resize((256, 256)),\n",
        "                              T.ToTensor(),\n",
        "                           ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "PAfvUkWEcEoE"
      },
      "outputs": [],
      "source": [
        "train_dataset = LungTumorSegmentationDataset(os.path.join(dataset_path, 'train'), image_transform, image_transform)\n",
        "val_dataset = LungTumorSegmentationDataset(os.path.join(dataset_path, 'val'), image_transform, image_transform)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IHQLI57Hc0ob",
        "outputId": "c74b9943-2379-4056-c28c-2660bec12fa7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of the training data: 1832\n",
            "Length of the validation data: 98\n"
          ]
        }
      ],
      "source": [
        "print('Length of the training data:', len(train_dataset))\n",
        "print('Length of the validation data:', len(val_dataset))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AGvSiUXwfOc4",
        "outputId": "68329485-9c58-4845-f0af-9cf5da9ca7c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of the training data: 1832\n",
            "Length of the validation data: 98\n"
          ]
        }
      ],
      "source": [
        "print('Length of the training data:', len(train_dataset))\n",
        "print('Length of the validation data:', len(val_dataset))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "qXdijYusfbTM"
      },
      "outputs": [],
      "source": [
        "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=False)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=32, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zYKKvIwIf7Bq",
        "outputId": "e73610c2-8a07-48ea-b5da-361298e2ca0c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of the first training sample & corresponding mask: torch.Size([1, 256, 256]) torch.Size([1, 256, 256])\n",
            "Shape of the first validation sample & corresponding mask: torch.Size([1, 256, 256]) torch.Size([1, 256, 256])\n"
          ]
        }
      ],
      "source": [
        "train_batches = iter(train_dataloader)\n",
        "val_batches = iter(val_dataloader)\n",
        "\n",
        "for train_sample, val_sample in zip(train_batches, val_batches):\n",
        "    print('Shape of the first training sample & corresponding mask:', train_sample[1][0].shape, train_sample[2][0].shape)\n",
        "    print('Shape of the first validation sample & corresponding mask:', val_sample[1][0].shape, val_sample[2][0].shape)\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Model Architecture**"
      ],
      "metadata": {
        "id": "Zu9tB-sdXj3e"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "QaGpeaiMOgy6"
      },
      "outputs": [],
      "source": [
        "def double_convolution(in_channels, out_channels):\n",
        "    \"\"\"\n",
        "    In the original paper implementation, the convolution operations were\n",
        "    not padded but we are padding them here. This is because, we need the\n",
        "    output result size to be same as input size.\n",
        "    \"\"\"\n",
        "    conv_op = nn.Sequential(\n",
        "                            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
        "                            nn.ReLU(inplace=True),\n",
        "\n",
        "                            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
        "                            nn.ReLU(inplace=True)\n",
        "                           )\n",
        "    return conv_op"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "p2zajPGeOEMu"
      },
      "outputs": [],
      "source": [
        "class UNet(nn.Module):\n",
        "\n",
        "\n",
        "    def __init__(self, num_classes):\n",
        "\n",
        "        super(UNet, self).__init__()\n",
        "\n",
        "        self.max_pool2d = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        # Contracting path.\n",
        "\n",
        "        # Each convolution is applied twice.\n",
        "        self.down_convolution_1 = double_convolution(1, 64)\n",
        "        self.down_convolution_2 = double_convolution(64, 128)\n",
        "        self.down_convolution_3 = double_convolution(128, 256)\n",
        "        self.down_convolution_4 = double_convolution(256, 512)\n",
        "        self.down_convolution_5 = double_convolution(512, 1024)\n",
        "\n",
        "\n",
        "        # Expanding path.\n",
        "        self.up_transpose_1 = nn.ConvTranspose2d(\n",
        "                                                in_channels=1024, out_channels=512,\n",
        "                                                kernel_size=2,\n",
        "                                                stride=2)\n",
        "\n",
        "        # Below, `in_channels` again becomes 1024 as we are concatinating.\n",
        "        self.up_convolution_1 = double_convolution(1024, 512)\n",
        "\n",
        "        self.up_transpose_2 = nn.ConvTranspose2d(\n",
        "                                                  in_channels=512, out_channels=256,\n",
        "                                                  kernel_size=2,\n",
        "                                                  stride=2)\n",
        "\n",
        "        self.up_convolution_2 = double_convolution(512, 256)\n",
        "\n",
        "        self.up_transpose_3 = nn.ConvTranspose2d(\n",
        "                                                  in_channels=256, out_channels=128,\n",
        "                                                  kernel_size=2,\n",
        "                                                  stride=2)\n",
        "\n",
        "        self.up_convolution_3 = double_convolution(256, 128)\n",
        "\n",
        "        self.up_transpose_4 = nn.ConvTranspose2d(\n",
        "                                                  in_channels=128, out_channels=64,\n",
        "                                                  kernel_size=2,\n",
        "                                                  stride=2)\n",
        "\n",
        "        self.up_convolution_4 = double_convolution(128, 64)\n",
        "\n",
        "        # output => `out_channels` as per the number of classes.\n",
        "        self.out = nn.Conv2d(\n",
        "                              in_channels=64, out_channels=num_classes,\n",
        "                              kernel_size=1\n",
        "                            )\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        down_1 = self.down_convolution_1(x)\n",
        "        down_2 = self.max_pool2d(down_1)\n",
        "        down_3 = self.down_convolution_2(down_2)\n",
        "        down_4 = self.max_pool2d(down_3)\n",
        "        down_5 = self.down_convolution_3(down_4)\n",
        "        down_6 = self.max_pool2d(down_5)\n",
        "        down_7 = self.down_convolution_4(down_6)\n",
        "        down_8 = self.max_pool2d(down_7)\n",
        "        down_9 = self.down_convolution_5(down_8)\n",
        "\n",
        "        # *** DO NOT APPLY MAX POOL TO down_9 ***\n",
        "\n",
        "        up_1 = self.up_transpose_1(down_9)\n",
        "        x = self.up_convolution_1(torch.cat([down_7, up_1], 1))\n",
        "\n",
        "        up_2 = self.up_transpose_2(x)\n",
        "        x = self.up_convolution_2(torch.cat([down_5, up_2], 1))\n",
        "\n",
        "        up_3 = self.up_transpose_3(x)\n",
        "        x = self.up_convolution_3(torch.cat([down_3, up_3], 1))\n",
        "\n",
        "        up_4 = self.up_transpose_4(x)\n",
        "        x = self.up_convolution_4(torch.cat([down_1, up_4], 1))\n",
        "\n",
        "        out = self.out(x)\n",
        "\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "fu4L1eT1kQ-2"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(test_loader, model, criterion, device):\n",
        "\n",
        "    model.eval()\n",
        "    test_loss = 0.0  # Initialize the test loss\n",
        "\n",
        "    with torch.no_grad():  # Disable gradient computation\n",
        "        for images_path, images, masks in test_loader:\n",
        "            images, masks = images.to(device), masks.to(device)\n",
        "\n",
        "            output = model(images)\n",
        "            loss = criterion(output, masks)\n",
        "\n",
        "            test_loss += loss.item()\n",
        "\n",
        "    test_loss /= len(test_loader)  # Average over all batches\n",
        "    print(f'Test Loss: {test_loss:.4f}')\n",
        "\n",
        "    return test_loss"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "whole_img_model = UNet(num_classes=1).to(device)\n",
        "whole_img_model.load_state_dict(torch.load(f\"/content/drive/MyDrive/unet_lung_segmentation_0.009356894996017218.pth\", map_location=device))\n",
        "whole_img_model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YDrSz3HX7Euj",
        "outputId": "2d2a63b9-2c18-4e7a-da3d-1436228419d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "UNet(\n",
              "  (max_pool2d): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (down_convolution_1): Sequential(\n",
              "    (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (3): ReLU(inplace=True)\n",
              "  )\n",
              "  (down_convolution_2): Sequential(\n",
              "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (3): ReLU(inplace=True)\n",
              "  )\n",
              "  (down_convolution_3): Sequential(\n",
              "    (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (3): ReLU(inplace=True)\n",
              "  )\n",
              "  (down_convolution_4): Sequential(\n",
              "    (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (3): ReLU(inplace=True)\n",
              "  )\n",
              "  (down_convolution_5): Sequential(\n",
              "    (0): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (3): ReLU(inplace=True)\n",
              "  )\n",
              "  (up_transpose_1): ConvTranspose2d(1024, 512, kernel_size=(2, 2), stride=(2, 2))\n",
              "  (up_convolution_1): Sequential(\n",
              "    (0): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (3): ReLU(inplace=True)\n",
              "  )\n",
              "  (up_transpose_2): ConvTranspose2d(512, 256, kernel_size=(2, 2), stride=(2, 2))\n",
              "  (up_convolution_2): Sequential(\n",
              "    (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (3): ReLU(inplace=True)\n",
              "  )\n",
              "  (up_transpose_3): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2))\n",
              "  (up_convolution_3): Sequential(\n",
              "    (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (3): ReLU(inplace=True)\n",
              "  )\n",
              "  (up_transpose_4): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2))\n",
              "  (up_convolution_4): Sequential(\n",
              "    (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (3): ReLU(inplace=True)\n",
              "  )\n",
              "  (out): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "izisRmqypeG2"
      },
      "outputs": [],
      "source": [
        "criterion = nn.BCEWithLogitsLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PKqHhMjTpi2F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4099e7c3-5de2-4bf8-ae08-b9abf134deed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.0094\n"
          ]
        }
      ],
      "source": [
        "# Evaluate on validation data\n",
        "val_loss = evaluate_model(val_dataloader, whole_img_model, criterion, device)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Detection**"
      ],
      "metadata": {
        "id": "EqNCkH7IgNlv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ultralytics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VOQTxe04eWss",
        "outputId": "4ecb8361-fd4c-49a5-ed5b-c4dd94f6e6c4"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.3.143-py3-none-any.whl.metadata (37 kB)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.0.2)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.11.0.86)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (11.2.1)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.15.3)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.21.0+cu124)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.2.2)\n",
            "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.14-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.58.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2025.4.26)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
            "Downloading ultralytics-8.3.143-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m41.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m87.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m72.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m47.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m69.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.14-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, ultralytics-thop, ultralytics\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 ultralytics-8.3.143 ultralytics-thop-2.0.14\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rSkpetiOjxnr",
        "outputId": "98337861-112c-43c6-ac2b-b120130f1276"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating new Ultralytics Settings v0.0.6 file âœ… \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_to_yolo_format(xmin, ymin, xmax, ymax, img_width, img_height):\n",
        "    x_center = (xmin + xmax) / 2 / img_width\n",
        "    y_center = (ymin + ymax) / 2 / img_height\n",
        "    width = (xmax - xmin) / img_width\n",
        "    height = (ymax - ymin) / img_height\n",
        "    return [0, x_center, y_center, width, height]"
      ],
      "metadata": {
        "id": "iGKDICUQB4Pv"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q '/content/LungTumorDetectionAndSegmentation.zip' -d '/content/dataset'"
      ],
      "metadata": {
        "id": "Pmd4Rm4MiIEv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_split(path,split):\n",
        "    image_dir = os.path.join(path, split, \"images\")\n",
        "    label_dir = os.path.join(path, split, \"detections\")\n",
        "\n",
        "    out_image_dir = os.path.join(path,\"images\",split)\n",
        "    out_label_dir = os.path.join(path,\"labels\",split)\n",
        "\n",
        "    os.makedirs(out_image_dir, exist_ok=True)\n",
        "    os.makedirs(out_label_dir, exist_ok=True)\n",
        "\n",
        "    for subject in os.listdir(image_dir):\n",
        "\n",
        "        subject_image_path = os.path.join(image_dir, subject)\n",
        "        subject_label_path = os.path.join(label_dir, subject)\n",
        "\n",
        "        for img_file in os.listdir(subject_image_path):\n",
        "            if not img_file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "                continue\n",
        "\n",
        "            img_path = os.path.join(subject_image_path, img_file)\n",
        "            label_file = img_file.rsplit(\".\", 1)[0] + \".txt\"\n",
        "            label_path = os.path.join(subject_label_path, label_file)\n",
        "\n",
        "            with Image.open(img_path) as img:\n",
        "                w, h = img.size\n",
        "\n",
        "            new_img_name = f\"{subject}_{img_file}\"\n",
        "            new_img_path = os.path.join(out_image_dir, new_img_name)\n",
        "            shutil.copy(img_path, new_img_path)\n",
        "\n",
        "\n",
        "            yolo_lines = []\n",
        "            if os.path.exists(label_path):\n",
        "                with open(label_path, \"r\") as f:\n",
        "                    for line in f:\n",
        "\n",
        "                        vals = list(map(float, line.strip().replace(',', ' ').split()))\n",
        "                        if len(vals) != 4:\n",
        "                            continue\n",
        "                        xmin, ymin, xmax, ymax = vals\n",
        "                        yolo_vals = convert_to_yolo_format(xmin, ymin, xmax, ymax, w, h)\n",
        "                        yolo_lines.append(\" \".join(map(str, yolo_vals)))\n",
        "\n",
        "            out_label_path = os.path.join(out_label_dir, new_img_name.rsplit(\".\", 1)[0] + \".txt\")\n",
        "            with open(out_label_path, \"w\") as f:\n",
        "                f.write(\"\\n\".join(yolo_lines))"
      ],
      "metadata": {
        "id": "zde6mzw4etdu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#path of dataset\n",
        "path_name='/content/dataset'\n",
        "process_split(path_name,'val')"
      ],
      "metadata": {
        "id": "anQz-aJ0ewn4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"lung_tumor.yaml\", \"w\") as f:\n",
        "    f.write(f\"\"\"train: {os.path.join(path_name, 'images', \"train\")}\n",
        "val: {os.path.join(path_name, 'images', \"val\")}\n",
        "nc: 1\n",
        "names: ['tumor']\n",
        "\"\"\")"
      ],
      "metadata": {
        "id": "TzVjxN_rif7x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#path of model\n",
        "model = YOLO('/content/best(2).pt')\n",
        "metrics = model.val(data='lung_tumor.yaml', split='val')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5AKKA6objkdu",
        "outputId": "7bc5197e-527e-426d-b996-e6f97f87dac9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.143 ğŸš€ Python-3.11.12 torch-2.6.0+cu124 CPU (Intel Xeon 2.20GHz)\n",
            "Model summary (fused): 72 layers, 3,005,843 parameters, 0 gradients, 8.1 GFLOPs\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 1132.3Â±277.1 MB/s, size: 34.7 KB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/dataset/labels/val.cache... 98 images, 20 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 98/98 [00:00<?, ?it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [01:30<00:00, 12.97s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         98         86      0.873      0.605      0.688      0.389\n",
            "Speed: 20.7ms preprocess, 884.3ms inference, 0.0ms loss, 1.3ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/val6\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"loss: {metrics.speed['loss']}\")\n",
        "print(f\"mAP@0.5: {metrics.box.map50:.4f}\")\n",
        "print(f\"mAP@0.5:0.95: {metrics.box.map:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tKTYD6nJjlZh",
        "outputId": "8b5f1dbf-4b4b-4f1f-afcd-28214c8eeff4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss: 0.00014389795013608372\n",
            "mAP@0.5: 0.6883\n",
            "mAP@0.5:0.95: 0.3887\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Validation on detected images (2 stages modelling)**"
      ],
      "metadata": {
        "id": "DZKQGXv7QUs3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO"
      ],
      "metadata": {
        "id": "7GvQHDAcUOfJ"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DoubleConv(nn.Module):\n",
        "\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "                                  nn.Conv2d(in_channels, out_channels, 3, padding=1, bias=False),\n",
        "                                  nn.BatchNorm2d(out_channels),\n",
        "                                  nn.ReLU(inplace=True),\n",
        "                                  nn.Dropout2d(0.15),  # Slightly increased dropout\n",
        "                                  nn.Conv2d(out_channels, out_channels, 3, padding=1, bias=False),\n",
        "                                  nn.BatchNorm2d(out_channels),\n",
        "                                  nn.ReLU(inplace=True)\n",
        "                                )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.conv(x)"
      ],
      "metadata": {
        "id": "9dUOCSYme3Qd"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class UNet(nn.Module):\n",
        "\n",
        "    def __init__(self, in_channels=3, out_channels=1, features=[32, 64, 128, 256]):\n",
        "        super().__init__()\n",
        "        self.downs = nn.ModuleList()\n",
        "        self.ups = nn.ModuleList()\n",
        "\n",
        "        # Downsampling path (encoder)\n",
        "        for feature in features:\n",
        "            self.downs.append(DoubleConv(in_channels, feature))\n",
        "            in_channels = feature\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        # Bottleneck\n",
        "        self.bottleneck = DoubleConv(features[-1], features[-1] * 2)\n",
        "\n",
        "        # Upsampling path (decoder)\n",
        "        for feature in reversed(features):\n",
        "            self.ups.append(nn.ConvTranspose2d(feature * 2, feature, kernel_size=2, stride=2))\n",
        "            self.ups.append(DoubleConv(feature * 2, feature))\n",
        "\n",
        "        # Final output layer\n",
        "        self.final_conv = nn.Conv2d(features[0], out_channels, kernel_size=1)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        skip_connections = []\n",
        "\n",
        "        for down in self.downs:\n",
        "            x = down(x)\n",
        "            skip_connections.append(x)\n",
        "            x = self.pool(x)\n",
        "\n",
        "        x = self.bottleneck(x)\n",
        "        skip_connections = skip_connections[::-1]\n",
        "\n",
        "        for idx in range(0, len(self.ups), 2):\n",
        "            x = self.ups[idx](x)  # transpose conv\n",
        "            skip_connection = skip_connections[idx // 2]\n",
        "\n",
        "            if x.shape != skip_connection.shape:\n",
        "                x = F.interpolate(x, size=skip_connection.shape[2:])\n",
        "\n",
        "            x = torch.cat((skip_connection, x), dim=1)\n",
        "            x = self.ups[idx + 1](x)\n",
        "\n",
        "        return self.final_conv(x)"
      ],
      "metadata": {
        "id": "-muAjqD9e6RZ"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_boxes_from_txt(txt_path):\n",
        "\n",
        "    boxes = []\n",
        "\n",
        "    with open(txt_path, 'r') as f:\n",
        "\n",
        "        for line in f:\n",
        "            xmin, ymin, xmax, ymax = map(float, line.strip().split(','))\n",
        "            boxes.append((int(xmin), int(ymin), int(xmax), int(ymax)))\n",
        "\n",
        "    return boxes"
      ],
      "metadata": {
        "id": "YJh4UQKyc8aN"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_iou(boxA, boxB):\n",
        "\n",
        "    xA = max(boxA[0], boxB[0])\n",
        "    yA = max(boxA[1], boxB[1])\n",
        "    xB = min(boxA[2], boxB[2])\n",
        "    yB = min(boxA[3], boxB[3])\n",
        "\n",
        "    interArea = max(0, xB - xA) * max(0, yB - yA)\n",
        "    boxAArea = max(1, (boxA[2] - boxA[0])) * max(1, (boxA[3] - boxA[1]))\n",
        "    boxBArea = max(1, (boxB[2] - boxB[0])) * max(1, (boxB[3] - boxB[1]))\n",
        "\n",
        "    iou = interArea / float(boxAArea + boxBArea - interArea + 1e-6)\n",
        "\n",
        "    return iou"
      ],
      "metadata": {
        "id": "S0UZUOVoc-K4"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def segment_detections(val_dataset, detection_model, segmentation_model, conf=0.3, iou_thresh=0.5):\n",
        "\n",
        "    segmentation_model.eval()\n",
        "\n",
        "    loss_fn = nn.BCEWithLogitsLoss()\n",
        "\n",
        "    total_loss = 0.0\n",
        "    count = 0\n",
        "\n",
        "\n",
        "    for img_path, _, _ in val_dataset:\n",
        "\n",
        "        img_cv2 = cv2.imread(img_path)\n",
        "\n",
        "        gt_boxes_path = img_path.replace('images', 'detections').replace('.png', '.txt')\n",
        "        try:\n",
        "            gt_boxes = load_boxes_from_txt(gt_boxes_path)\n",
        "        except FileNotFoundError:\n",
        "            continue\n",
        "\n",
        "        mask_path = img_path.replace('images', 'masks')\n",
        "        mask_gt = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "        results = detection_model(img_path, conf=conf)\n",
        "        pred_boxes = results[0].boxes\n",
        "\n",
        "\n",
        "        for pred_box in pred_boxes:\n",
        "\n",
        "            x1, y1, x2, y2 = map(int, pred_box.xyxy[0])\n",
        "\n",
        "            best_iou = 0\n",
        "            best_gt_box = None\n",
        "\n",
        "            for gt_box in gt_boxes:\n",
        "\n",
        "                iou = compute_iou((x1, y1, x2, y2), gt_box[:4])\n",
        "                if iou > best_iou:\n",
        "                    best_iou = iou\n",
        "                    best_gt_box = gt_box\n",
        "\n",
        "            if best_iou < iou_thresh:\n",
        "                continue\n",
        "\n",
        "            crop_img = img_cv2[y1:y2, x1:x2]\n",
        "            crop_mask = mask_gt[y1:y2, x1:x2]\n",
        "\n",
        "            if crop_img.size == 0 or crop_mask.size == 0:\n",
        "                continue\n",
        "\n",
        "            crop_img_rgb = cv2.cvtColor(crop_img, cv2.COLOR_BGR2RGB)\n",
        "            image_pil = Image.fromarray(crop_img_rgb).resize((64, 64))\n",
        "\n",
        "            input_tensor = torch.tensor(np.transpose(np.array(image_pil).astype(np.float32) / 255.0, (2, 0, 1)))\n",
        "            input_tensor = input_tensor.unsqueeze(0).to(next(segmentation_model.parameters()).device)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                output = segmentation_model(input_tensor)\n",
        "\n",
        "            pred_mask = output.squeeze(0)#.squeeze(0)  # shape: (H, W)\n",
        "            # if pred_mask.dim() == 2:  # [64, 64]\n",
        "            #    pred_mask = pred_mask.unsqueeze(0)\n",
        "\n",
        "            target_mask = Image.fromarray(crop_mask).resize((64, 64))\n",
        "            target_tensor = torch.tensor(np.array(target_mask).astype(np.float32) / 255.0)\n",
        "            target_tensor = target_tensor.unsqueeze(0).to(pred_mask.device)\n",
        "\n",
        "            loss = loss_fn(pred_mask, target_tensor)\n",
        "            total_loss += loss.item()\n",
        "            count += 1\n",
        "\n",
        "    avg_loss = total_loss / count if count > 0 else 0\n",
        "    print(f\"Average segmentation loss over dataset: {avg_loss:.4f}\")\n",
        "\n",
        "    return avg_loss"
      ],
      "metadata": {
        "id": "j33X-hFigV9O"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "detection_model = YOLO('/content/best(2).pt')"
      ],
      "metadata": {
        "id": "EIxRbUbJUDt2"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "segmentation_model = UNet().to(device)\n",
        "segmentation_model.load_state_dict(torch.load(f\"/content/drive/MyDrive/best_unet_cropped.pth\", map_location=device))"
      ],
      "metadata": {
        "id": "YlnoXcQ5e9bz",
        "outputId": "43cba381-c330-41ed-8466-2f5fc5901f33",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_loss = segment_detections(val_dataset, detection_model, segmentation_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8-AJ3EH3T7cJ",
        "outputId": "2623238f-06cc-44b1-9af6-8740877fa5a5"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/drive/MyDrive/LungTumorDetectionAndSegmentation/val/images/Subject_59/90.png: 1024x1024 (no detections), 654.6ms\n",
            "Speed: 10.5ms preprocess, 654.6ms inference, 0.9ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/LungTumorDetectionAndSegmentation/val/images/Subject_59/88.png: 1024x1024 1 tumor, 600.4ms\n",
            "Speed: 17.7ms preprocess, 600.4ms inference, 2.6ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/LungTumorDetectionAndSegmentation/val/images/Subject_59/84.png: 1024x1024 1 tumor, 584.8ms\n",
            "Speed: 15.0ms preprocess, 584.8ms inference, 1.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/LungTumorDetectionAndSegmentation/val/images/Subject_59/82.png: 1024x1024 1 tumor, 613.2ms\n",
            "Speed: 16.0ms preprocess, 613.2ms inference, 1.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/LungTumorDetectionAndSegmentation/val/images/Subject_59/79.png: 1024x1024 1 tumor, 806.1ms\n",
            "Speed: 17.0ms preprocess, 806.1ms inference, 1.8ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/LungTumorDetectionAndSegmentation/val/images/Subject_59/77.png: 1024x1024 1 tumor, 887.9ms\n",
            "Speed: 12.0ms preprocess, 887.9ms inference, 1.8ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/LungTumorDetectionAndSegmentation/val/images/Subject_59/80.png: 1024x1024 1 tumor, 890.6ms\n",
            "Speed: 19.3ms preprocess, 890.6ms inference, 2.0ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/LungTumorDetectionAndSegmentation/val/images/Subject_59/76.png: 1024x1024 1 tumor, 878.5ms\n",
            "Speed: 22.0ms preprocess, 878.5ms inference, 2.0ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/LungTumorDetectionAndSegmentation/val/images/Subject_59/83.png: 1024x1024 1 tumor, 745.8ms\n",
            "Speed: 12.3ms preprocess, 745.8ms inference, 1.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/LungTumorDetectionAndSegmentation/val/images/Subject_59/87.png: 1024x1024 1 tumor, 623.3ms\n",
            "Speed: 16.8ms preprocess, 623.3ms inference, 1.5ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/LungTumorDetectionAndSegmentation/val/images/Subject_59/78.png: 1024x1024 2 tumors, 606.6ms\n",
            "Speed: 16.4ms preprocess, 606.6ms inference, 1.5ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/LungTumorDetectionAndSegmentation/val/images/Subject_59/89.png: 1024x1024 (no detections), 611.9ms\n",
            "Speed: 14.6ms preprocess, 611.9ms inference, 1.0ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/LungTumorDetectionAndSegmentation/val/images/Subject_59/86.png: 1024x1024 2 tumors, 594.4ms\n",
            "Speed: 10.2ms preprocess, 594.4ms inference, 1.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/LungTumorDetectionAndSegmentation/val/images/Subject_59/81.png: 1024x1024 1 tumor, 593.6ms\n",
            "Speed: 9.3ms preprocess, 593.6ms inference, 1.3ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/LungTumorDetectionAndSegmentation/val/images/Subject_59/85.png: 1024x1024 1 tumor, 595.0ms\n",
            "Speed: 8.9ms preprocess, 595.0ms inference, 1.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/LungTumorDetectionAndSegmentation/val/images/Subject_59/75.png: 1024x1024 (no detections), 609.6ms\n",
            "Speed: 12.4ms preprocess, 609.6ms inference, 0.9ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/LungTumorDetectionAndSegmentation/val/images/Subject_57/214.png: 1024x1024 1 tumor, 614.3ms\n",
            "Speed: 11.1ms preprocess, 614.3ms inference, 2.1ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/LungTumorDetectionAndSegmentation/val/images/Subject_57/202.png: 1024x1024 2 tumors, 602.4ms\n",
            "Speed: 16.0ms preprocess, 602.4ms inference, 1.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/LungTumorDetectionAndSegmentation/val/images/Subject_57/218.png: 1024x1024 1 tumor, 604.1ms\n",
            "Speed: 10.5ms preprocess, 604.1ms inference, 1.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/LungTumorDetectionAndSegmentation/val/images/Subject_57/209.png: 1024x1024 1 tumor, 627.8ms\n",
            "Speed: 16.0ms preprocess, 627.8ms inference, 1.3ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/LungTumorDetectionAndSegmentation/val/images/Subject_57/208.png: 1024x1024 1 tumor, 562.4ms\n",
            "Speed: 11.6ms preprocess, 562.4ms inference, 1.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/LungTumorDetectionAndSegmentation/val/images/Subject_57/210.png: 1024x1024 1 tumor, 610.0ms\n",
            "Speed: 17.9ms preprocess, 610.0ms inference, 1.3ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/LungTumorDetectionAndSegmentation/val/images/Subject_57/201.png: 1024x1024 (no detections), 845.7ms\n",
            "Speed: 16.5ms preprocess, 845.7ms inference, 4.5ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/LungTumorDetectionAndSegmentation/val/images/Subject_57/217.png: 1024x1024 1 tumor, 1306.2ms\n",
            "Speed: 36.3ms preprocess, 1306.2ms inference, 1.9ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/LungTumorDetectionAndSegmentation/val/images/Subject_57/213.png: 1024x1024 2 tumors, 890.4ms\n",
            "Speed: 11.9ms preprocess, 890.4ms inference, 2.1ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/LungTumorDetectionAndSegmentation/val/images/Subject_57/203.png: 1024x1024 1 tumor, 905.1ms\n",
            "Speed: 21.0ms preprocess, 905.1ms inference, 2.2ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/LungTumorDetectionAndSegmentation/val/images/Subject_57/211.png: 1024x1024 1 tumor, 773.3ms\n",
            "Speed: 23.3ms preprocess, 773.3ms inference, 1.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/LungTumorDetectionAndSegmentation/val/images/Subject_57/204.png: 1024x1024 1 tumor, 609.9ms\n",
            "Speed: 13.6ms preprocess, 609.9ms inference, 1.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/LungTumorDetectionAndSegmentation/val/images/Subject_57/207.png: 1024x1024 1 tumor, 611.0ms\n",
            "Speed: 16.9ms preprocess, 611.0ms inference, 1.6ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/LungTumorDetectionAndSegmentation/val/images/Subject_57/212.png: 1024x1024 1 tumor, 606.9ms\n",
            "Speed: 8.7ms preprocess, 606.9ms inference, 1.7ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/LungTumorDetectionAndSegmentation/val/images/Subject_57/216.png: 1024x1024 1 tumor, 618.0ms\n",
            "Speed: 19.1ms preprocess, 618.0ms inference, 1.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/LungTumorDetectionAndSegmentation/val/images/Subject_57/215.png: 1024x1024 1 tumor, 593.1ms\n",
            "Speed: 14.8ms preprocess, 593.1ms inference, 1.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/LungTumorDetectionAndSegmentation/val/images/Subject_57/205.png: 1024x1024 1 tumor, 592.6ms\n",
            "Speed: 15.1ms preprocess, 592.6ms inference, 1.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/LungTumorDetectionAndSegmentation/val/images/Subject_57/206.png: 1024x1024 1 tumor, 601.6ms\n",
            "Speed: 16.7ms preprocess, 601.6ms inference, 1.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/LungTumorDetectionAndSegmentation/val/images/Subject_58/290.png: 1024x1024 1 tumor, 588.1ms\n",
            "Speed: 14.2ms preprocess, 588.1ms inference, 1.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/LungTumorDetectionAndSegmentation/val/images/Subject_58/282.png: 1024x1024 1 tumor, 595.2ms\n",
            "Speed: 9.0ms preprocess, 595.2ms inference, 1.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/LungTumorDetectionAndSegmentation/val/images/Subject_58/269.png: 1024x1024 (no detections), 603.0ms\n",
            "Speed: 14.7ms preprocess, 603.0ms inference, 0.9ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/LungTumorDetectionAndSegmentation/val/images/Subject_58/289.png: 1024x1024 1 tumor, 586.2ms\n",
            "Speed: 16.7ms preprocess, 586.2ms inference, 1.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/LungTumorDetectionAndSegmentation/val/images/Subject_58/273.png: 1024x1024 (no detections), 610.9ms\n",
            "Speed: 16.6ms preprocess, 610.9ms inference, 0.9ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/LungTumorDetectionAndSegmentation/val/images/Subject_58/278.png: 1024x1024 1 tumor, 550.2ms\n",
            "Speed: 10.2ms preprocess, 550.2ms inference, 1.3ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/LungTumorDetectionAndSegmentation/val/images/Subject_58/280.png: 1024x1024 1 tumor, 543.9ms\n",
            "Speed: 9.0ms preprocess, 543.9ms inference, 1.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/LungTumorDetectionAndSegmentation/val/images/Subject_58/276.png: 1024x1024 1 tumor, 901.9ms\n",
            "Speed: 16.9ms preprocess, 901.9ms inference, 1.8ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/LungTumorDetectionAndSegmentation/val/images/Subject_58/274.png: 1024x1024 1 tumor, 893.2ms\n",
            "Speed: 18.5ms preprocess, 893.2ms inference, 1.6ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/LungTumorDetectionAndSegmentation/val/images/Subject_58/270.png: 1024x1024 (no detections), 908.8ms\n",
            "Speed: 21.5ms preprocess, 908.8ms inference, 1.1ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/LungTumorDetectionAndSegmentation/val/images/Subject_58/275.png: 1024x1024 1 tumor, 915.8ms\n",
            "Speed: 21.0ms preprocess, 915.8ms inference, 2.1ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/LungTumorDetectionAndSegmentation/val/images/Subject_58/271.png: 1024x1024 (no detections), 637.6ms\n",
            "Speed: 21.6ms preprocess, 637.6ms inference, 0.8ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/LungTumorDetectionAndSegmentation/val/images/Subject_58/283.png: 1024x1024 1 tumor, 557.7ms\n",
            "Speed: 9.1ms preprocess, 557.7ms inference, 1.3ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/LungTumorDetectionAndSegmentation/val/images/Subject_58/284.png: 1024x1024 1 tumor, 568.1ms\n",
            "Speed: 10.1ms preprocess, 568.1ms inference, 1.3ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/LungTumorDetectionAndSegmentation/val/images/Subject_58/272.png: 1024x1024 (no detections), 651.6ms\n",
            "Speed: 16.4ms preprocess, 651.6ms inference, 0.9ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/LungTumorDetectionAndSegmentation/val/images/Subject_58/287.png: 1024x1024 1 tumor, 601.1ms\n",
            "Speed: 15.6ms preprocess, 601.1ms inference, 1.3ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/LungTumorDetectionAndSegmentation/val/images/Subject_58/288.png: 1024x1024 1 tumor, 607.4ms\n",
            "Speed: 8.7ms preprocess, 607.4ms inference, 1.5ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/LungTumorDetectionAndSegmentation/val/images/Subject_58/285.png: 1024x1024 1 tumor, 596.7ms\n",
            "Speed: 8.8ms preprocess, 596.7ms inference, 1.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/LungTumorDetectionAndSegmentation/val/images/Subject_58/277.png: 1024x1024 1 tumor, 589.0ms\n",
            "Speed: 15.4ms preprocess, 589.0ms inference, 1.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/LungTumorDetectionAndSegmentation/val/images/Subject_58/279.png: 1024x1024 1 tumor, 602.7ms\n",
            "Speed: 9.5ms preprocess, 602.7ms inference, 1.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/LungTumorDetectionAndSegmentation/val/images/Subject_58/281.png: 1024x1024 1 tumor, 618.1ms\n",
            "Speed: 15.0ms preprocess, 618.1ms inference, 1.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/LungTumorDetectionAndSegmentation/val/images/Subject_58/286.png: 1024x1024 1 tumor, 591.8ms\n",
            "Speed: 9.8ms preprocess, 591.8ms inference, 1.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/LungTumorDetectionAndSegmentation/val/images/Subject_58/294.png: 1024x1024 1 tumor, 606.5ms\n",
            "Speed: 17.4ms preprocess, 606.5ms inference, 1.7ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/LungTumorDetectionAndSegmentation/val/images/Subject_58/299.png: 1024x1024 (no detections), 575.3ms\n",
            "Speed: 9.2ms preprocess, 575.3ms inference, 1.1ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/LungTumorDetectionAndSegmentation/val/images/Subject_58/297.png: 1024x1024 1 tumor, 546.8ms\n",
            "Speed: 9.3ms preprocess, 546.8ms inference, 1.3ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/LungTumorDetectionAndSegmentation/val/images/Subject_58/303.png: 1024x1024 (no detections), 638.3ms\n",
            "Speed: 9.0ms preprocess, 638.3ms inference, 1.2ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/LungTumorDetectionAndSegmentation/val/images/Subject_58/301.png: 1024x1024 (no detections), 829.7ms\n",
            "Speed: 13.2ms preprocess, 829.7ms inference, 1.1ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/LungTumorDetectionAndSegmentation/val/images/Subject_58/292.png: 1024x1024 1 tumor, 825.3ms\n",
            "Speed: 11.8ms preprocess, 825.3ms inference, 1.7ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/LungTumorDetectionAndSegmentation/val/images/Subject_58/295.png: 1024x1024 1 tumor, 809.1ms\n",
            "Speed: 12.0ms preprocess, 809.1ms inference, 1.7ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/LungTumorDetectionAndSegmentation/val/images/Subject_58/293.png: 1024x1024 1 tumor, 832.7ms\n",
            "Speed: 18.9ms preprocess, 832.7ms inference, 1.8ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/LungTumorDetectionAndSegmentation/val/images/Subject_58/298.png: 1024x1024 (no detections), 726.0ms\n",
            "Speed: 11.9ms preprocess, 726.0ms inference, 0.9ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/LungTumorDetectionAndSegmentation/val/images/Subject_58/296.png: 1024x1024 1 tumor, 607.2ms\n",
            "Speed: 18.4ms preprocess, 607.2ms inference, 1.6ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/LungTumorDetectionAndSegmentation/val/images/Subject_58/300.png: 1024x1024 1 tumor, 587.6ms\n",
            "Speed: 16.1ms preprocess, 587.6ms inference, 1.3ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/LungTumorDetectionAndSegmentation/val/images/Subject_58/302.png: 1024x1024 (no detections), 624.0ms\n",
            "Speed: 9.5ms preprocess, 624.0ms inference, 1.0ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/LungTumorDetectionAndSegmentation/val/images/Subject_58/291.png: 1024x1024 1 tumor, 569.2ms\n",
            "Speed: 10.6ms preprocess, 569.2ms inference, 1.5ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/LungTumorDetectionAndSegmentation/val/images/Subject_60/53.png: 1024x1024 (no detections), 586.1ms\n",
            "Speed: 14.3ms preprocess, 586.1ms inference, 0.9ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/LungTumorDetectionAndSegmentation/val/images/Subject_60/49.png: 1024x1024 1 tumor, 614.5ms\n",
            "Speed: 16.8ms preprocess, 614.5ms inference, 1.3ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/LungTumorDetectionAndSegmentation/val/images/Subject_60/48.png: 1024x1024 1 tumor, 613.1ms\n",
            "Speed: 16.6ms preprocess, 613.1ms inference, 1.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/LungTumorDetectionAndSegmentation/val/images/Subject_60/51.png: 1024x1024 (no detections), 598.4ms\n",
            "Speed: 20.0ms preprocess, 598.4ms inference, 0.9ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/LungTumorDetectionAndSegmentation/val/images/Subject_60/54.png: 1024x1024 (no detections), 609.4ms\n",
            "Speed: 16.3ms preprocess, 609.4ms inference, 1.0ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/LungTumorDetectionAndSegmentation/val/images/Subject_60/46.png: 1024x1024 1 tumor, 622.1ms\n",
            "Speed: 16.6ms preprocess, 622.1ms inference, 1.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/LungTumorDetectionAndSegmentation/val/images/Subject_60/47.png: 1024x1024 (no detections), 594.3ms\n",
            "Speed: 14.7ms preprocess, 594.3ms inference, 0.9ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/LungTumorDetectionAndSegmentation/val/images/Subject_60/52.png: 1024x1024 (no detections), 610.8ms\n",
            "Speed: 9.5ms preprocess, 610.8ms inference, 0.9ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/LungTumorDetectionAndSegmentation/val/images/Subject_60/50.png: 1024x1024 (no detections), 545.5ms\n",
            "Speed: 9.1ms preprocess, 545.5ms inference, 1.0ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "Average segmentation loss over dataset: 0.4751\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.47511487282239473"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    }
  ]
}