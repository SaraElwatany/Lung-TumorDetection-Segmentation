{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO8XAhtDZFHsE2kXtqeFFll",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SaraElwatany/Lung-TumorDetection-Segmentation/blob/main/comparison.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "f1h22hs0Oic7"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import torch\n",
        "import shutil\n",
        "import torch.nn as nn\n",
        "from PIL import Image\n",
        "from google.colab import drive\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision.transforms as T\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import Dataset, DataLoader, random_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kjhIHHVlXyCR",
        "outputId": "8132b959-ae79-459b-a280-7dde5b9f837c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "i_zlPVxYX5Wf"
      },
      "outputs": [],
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sdWWrZNadOiV"
      },
      "source": [
        "#### **DataLoading & Splitting**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "E4-J0tPoYTEZ"
      },
      "outputs": [],
      "source": [
        "dataset_path = '/content/drive/MyDrive/LungTumorDetectionAndSegmentation'"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Validation on Whole Images**"
      ],
      "metadata": {
        "id": "ayGrAmJ7gI3T"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "5VJ0sUlQY9hh"
      },
      "outputs": [],
      "source": [
        "class LungTumorSegmentationDataset(Dataset):\n",
        "\n",
        "    def __init__(self, root_path, transform=None, mask_transform=None):\n",
        "\n",
        "        self.images = []\n",
        "        for subject in os.listdir(os.path.join(root_path, 'images')):\n",
        "            subject_path = os.path.join(root_path, 'images', subject)\n",
        "            for image_file in os.listdir(subject_path):\n",
        "                self.images.append(os.path.join(subject_path, image_file))\n",
        "\n",
        "        self.masks = [img_path.replace('images', 'masks') for img_path in self.images]\n",
        "        self.transform = transform\n",
        "        self.mask_transform = mask_transform\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "\n",
        "        image_path = self.images[idx]\n",
        "        mask_path = self.masks[idx]\n",
        "\n",
        "        image = Image.open(image_path).convert(\"L\")  # grayscale image\n",
        "        mask = Image.open(mask_path).convert(\"L\")    # mask as single-channel\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        if self.mask_transform:\n",
        "            mask = self.mask_transform(mask)\n",
        "            mask = (mask > 0.5).float()  # Ensure binary values\n",
        "\n",
        "        return image_path, image, mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "IgDRAQseciyk"
      },
      "outputs": [],
      "source": [
        "image_transform = T.Compose([\n",
        "                              T.Resize((256, 256)),\n",
        "                              T.ToTensor(),\n",
        "                           ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "PAfvUkWEcEoE"
      },
      "outputs": [],
      "source": [
        "train_dataset = LungTumorSegmentationDataset(os.path.join(dataset_path, 'train'), image_transform, image_transform)\n",
        "val_dataset = LungTumorSegmentationDataset(os.path.join(dataset_path, 'val'), image_transform, image_transform)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IHQLI57Hc0ob",
        "outputId": "c74b9943-2379-4056-c28c-2660bec12fa7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of the training data: 1832\n",
            "Length of the validation data: 98\n"
          ]
        }
      ],
      "source": [
        "print('Length of the training data:', len(train_dataset))\n",
        "print('Length of the validation data:', len(val_dataset))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AGvSiUXwfOc4",
        "outputId": "68329485-9c58-4845-f0af-9cf5da9ca7c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of the training data: 1832\n",
            "Length of the validation data: 98\n"
          ]
        }
      ],
      "source": [
        "print('Length of the training data:', len(train_dataset))\n",
        "print('Length of the validation data:', len(val_dataset))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "qXdijYusfbTM"
      },
      "outputs": [],
      "source": [
        "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=False)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=32, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zYKKvIwIf7Bq",
        "outputId": "e73610c2-8a07-48ea-b5da-361298e2ca0c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of the first training sample & corresponding mask: torch.Size([1, 256, 256]) torch.Size([1, 256, 256])\n",
            "Shape of the first validation sample & corresponding mask: torch.Size([1, 256, 256]) torch.Size([1, 256, 256])\n"
          ]
        }
      ],
      "source": [
        "train_batches = iter(train_dataloader)\n",
        "val_batches = iter(val_dataloader)\n",
        "\n",
        "for train_sample, val_sample in zip(train_batches, val_batches):\n",
        "    print('Shape of the first training sample & corresponding mask:', train_sample[1][0].shape, train_sample[2][0].shape)\n",
        "    print('Shape of the first validation sample & corresponding mask:', val_sample[1][0].shape, val_sample[2][0].shape)\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Model Architecture**"
      ],
      "metadata": {
        "id": "Zu9tB-sdXj3e"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "QaGpeaiMOgy6"
      },
      "outputs": [],
      "source": [
        "def double_convolution(in_channels, out_channels):\n",
        "    \"\"\"\n",
        "    In the original paper implementation, the convolution operations were\n",
        "    not padded but we are padding them here. This is because, we need the\n",
        "    output result size to be same as input size.\n",
        "    \"\"\"\n",
        "    conv_op = nn.Sequential(\n",
        "                            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
        "                            nn.ReLU(inplace=True),\n",
        "\n",
        "                            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
        "                            nn.ReLU(inplace=True)\n",
        "                           )\n",
        "    return conv_op"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "p2zajPGeOEMu"
      },
      "outputs": [],
      "source": [
        "class UNet(nn.Module):\n",
        "\n",
        "\n",
        "    def __init__(self, num_classes):\n",
        "\n",
        "        super(UNet, self).__init__()\n",
        "\n",
        "        self.max_pool2d = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        # Contracting path.\n",
        "\n",
        "        # Each convolution is applied twice.\n",
        "        self.down_convolution_1 = double_convolution(1, 64)\n",
        "        self.down_convolution_2 = double_convolution(64, 128)\n",
        "        self.down_convolution_3 = double_convolution(128, 256)\n",
        "        self.down_convolution_4 = double_convolution(256, 512)\n",
        "        self.down_convolution_5 = double_convolution(512, 1024)\n",
        "\n",
        "\n",
        "        # Expanding path.\n",
        "        self.up_transpose_1 = nn.ConvTranspose2d(\n",
        "                                                in_channels=1024, out_channels=512,\n",
        "                                                kernel_size=2,\n",
        "                                                stride=2)\n",
        "\n",
        "        # Below, `in_channels` again becomes 1024 as we are concatinating.\n",
        "        self.up_convolution_1 = double_convolution(1024, 512)\n",
        "\n",
        "        self.up_transpose_2 = nn.ConvTranspose2d(\n",
        "                                                  in_channels=512, out_channels=256,\n",
        "                                                  kernel_size=2,\n",
        "                                                  stride=2)\n",
        "\n",
        "        self.up_convolution_2 = double_convolution(512, 256)\n",
        "\n",
        "        self.up_transpose_3 = nn.ConvTranspose2d(\n",
        "                                                  in_channels=256, out_channels=128,\n",
        "                                                  kernel_size=2,\n",
        "                                                  stride=2)\n",
        "\n",
        "        self.up_convolution_3 = double_convolution(256, 128)\n",
        "\n",
        "        self.up_transpose_4 = nn.ConvTranspose2d(\n",
        "                                                  in_channels=128, out_channels=64,\n",
        "                                                  kernel_size=2,\n",
        "                                                  stride=2)\n",
        "\n",
        "        self.up_convolution_4 = double_convolution(128, 64)\n",
        "\n",
        "        # output => `out_channels` as per the number of classes.\n",
        "        self.out = nn.Conv2d(\n",
        "                              in_channels=64, out_channels=num_classes,\n",
        "                              kernel_size=1\n",
        "                            )\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        down_1 = self.down_convolution_1(x)\n",
        "        down_2 = self.max_pool2d(down_1)\n",
        "        down_3 = self.down_convolution_2(down_2)\n",
        "        down_4 = self.max_pool2d(down_3)\n",
        "        down_5 = self.down_convolution_3(down_4)\n",
        "        down_6 = self.max_pool2d(down_5)\n",
        "        down_7 = self.down_convolution_4(down_6)\n",
        "        down_8 = self.max_pool2d(down_7)\n",
        "        down_9 = self.down_convolution_5(down_8)\n",
        "\n",
        "        # *** DO NOT APPLY MAX POOL TO down_9 ***\n",
        "\n",
        "        up_1 = self.up_transpose_1(down_9)\n",
        "        x = self.up_convolution_1(torch.cat([down_7, up_1], 1))\n",
        "\n",
        "        up_2 = self.up_transpose_2(x)\n",
        "        x = self.up_convolution_2(torch.cat([down_5, up_2], 1))\n",
        "\n",
        "        up_3 = self.up_transpose_3(x)\n",
        "        x = self.up_convolution_3(torch.cat([down_3, up_3], 1))\n",
        "\n",
        "        up_4 = self.up_transpose_4(x)\n",
        "        x = self.up_convolution_4(torch.cat([down_1, up_4], 1))\n",
        "\n",
        "        out = self.out(x)\n",
        "\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "fu4L1eT1kQ-2"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(test_loader, model, criterion, device):\n",
        "\n",
        "    model.eval()\n",
        "    test_loss = 0.0  # Initialize the test loss\n",
        "\n",
        "    with torch.no_grad():  # Disable gradient computation\n",
        "        for images_path, images, masks in test_loader:\n",
        "            images, masks = images.to(device), masks.to(device)\n",
        "\n",
        "            output = model(images)\n",
        "            loss = criterion(output, masks)\n",
        "\n",
        "            test_loss += loss.item()\n",
        "\n",
        "    test_loss /= len(test_loader)  # Average over all batches\n",
        "    print(f'Test Loss: {test_loss:.4f}')\n",
        "\n",
        "    return test_loss"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "whole_img_model = UNet(num_classes=1).to(device)\n",
        "whole_img_model.load_state_dict(torch.load(f\"/content/drive/MyDrive/unet_lung_segmentation_0.009356894996017218.pth\", map_location=device))\n",
        "whole_img_model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YDrSz3HX7Euj",
        "outputId": "2d2a63b9-2c18-4e7a-da3d-1436228419d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "UNet(\n",
              "  (max_pool2d): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (down_convolution_1): Sequential(\n",
              "    (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (3): ReLU(inplace=True)\n",
              "  )\n",
              "  (down_convolution_2): Sequential(\n",
              "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (3): ReLU(inplace=True)\n",
              "  )\n",
              "  (down_convolution_3): Sequential(\n",
              "    (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (3): ReLU(inplace=True)\n",
              "  )\n",
              "  (down_convolution_4): Sequential(\n",
              "    (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (3): ReLU(inplace=True)\n",
              "  )\n",
              "  (down_convolution_5): Sequential(\n",
              "    (0): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (3): ReLU(inplace=True)\n",
              "  )\n",
              "  (up_transpose_1): ConvTranspose2d(1024, 512, kernel_size=(2, 2), stride=(2, 2))\n",
              "  (up_convolution_1): Sequential(\n",
              "    (0): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (3): ReLU(inplace=True)\n",
              "  )\n",
              "  (up_transpose_2): ConvTranspose2d(512, 256, kernel_size=(2, 2), stride=(2, 2))\n",
              "  (up_convolution_2): Sequential(\n",
              "    (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (3): ReLU(inplace=True)\n",
              "  )\n",
              "  (up_transpose_3): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2))\n",
              "  (up_convolution_3): Sequential(\n",
              "    (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (3): ReLU(inplace=True)\n",
              "  )\n",
              "  (up_transpose_4): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2))\n",
              "  (up_convolution_4): Sequential(\n",
              "    (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (3): ReLU(inplace=True)\n",
              "  )\n",
              "  (out): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "izisRmqypeG2"
      },
      "outputs": [],
      "source": [
        "criterion = nn.BCEWithLogitsLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PKqHhMjTpi2F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4099e7c3-5de2-4bf8-ae08-b9abf134deed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.0094\n"
          ]
        }
      ],
      "source": [
        "# Evaluate on validation data\n",
        "val_loss = evaluate_model(val_dataloader, whole_img_model, criterion, device)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Detection**"
      ],
      "metadata": {
        "id": "EqNCkH7IgNlv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ultralytics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VOQTxe04eWss",
        "outputId": "4ecb8361-fd4c-49a5-ed5b-c4dd94f6e6c4"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.3.143-py3-none-any.whl.metadata (37 kB)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.0.2)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.11.0.86)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (11.2.1)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.15.3)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.21.0+cu124)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.2.2)\n",
            "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.14-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.58.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2025.4.26)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
            "Downloading ultralytics-8.3.143-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m41.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m87.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m72.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m47.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m69.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.14-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, ultralytics-thop, ultralytics\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 ultralytics-8.3.143 ultralytics-thop-2.0.14\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rSkpetiOjxnr",
        "outputId": "98337861-112c-43c6-ac2b-b120130f1276"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating new Ultralytics Settings v0.0.6 file ✅ \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_to_yolo_format(xmin, ymin, xmax, ymax, img_width, img_height):\n",
        "    x_center = (xmin + xmax) / 2 / img_width\n",
        "    y_center = (ymin + ymax) / 2 / img_height\n",
        "    width = (xmax - xmin) / img_width\n",
        "    height = (ymax - ymin) / img_height\n",
        "    return [0, x_center, y_center, width, height]"
      ],
      "metadata": {
        "id": "iGKDICUQB4Pv"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q '/content/LungTumorDetectionAndSegmentation.zip' -d '/content/dataset'"
      ],
      "metadata": {
        "id": "Pmd4Rm4MiIEv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_split(path,split):\n",
        "    image_dir = os.path.join(path, split, \"images\")\n",
        "    label_dir = os.path.join(path, split, \"detections\")\n",
        "\n",
        "    out_image_dir = os.path.join(path,\"images\",split)\n",
        "    out_label_dir = os.path.join(path,\"labels\",split)\n",
        "\n",
        "    os.makedirs(out_image_dir, exist_ok=True)\n",
        "    os.makedirs(out_label_dir, exist_ok=True)\n",
        "\n",
        "    for subject in os.listdir(image_dir):\n",
        "\n",
        "        subject_image_path = os.path.join(image_dir, subject)\n",
        "        subject_label_path = os.path.join(label_dir, subject)\n",
        "\n",
        "        for img_file in os.listdir(subject_image_path):\n",
        "            if not img_file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "                continue\n",
        "\n",
        "            img_path = os.path.join(subject_image_path, img_file)\n",
        "            label_file = img_file.rsplit(\".\", 1)[0] + \".txt\"\n",
        "            label_path = os.path.join(subject_label_path, label_file)\n",
        "\n",
        "            with Image.open(img_path) as img:\n",
        "                w, h = img.size\n",
        "\n",
        "            new_img_name = f\"{subject}_{img_file}\"\n",
        "            new_img_path = os.path.join(out_image_dir, new_img_name)\n",
        "            shutil.copy(img_path, new_img_path)\n",
        "\n",
        "\n",
        "            yolo_lines = []\n",
        "            if os.path.exists(label_path):\n",
        "                with open(label_path, \"r\") as f:\n",
        "                    for line in f:\n",
        "\n",
        "                        vals = list(map(float, line.strip().replace(',', ' ').split()))\n",
        "                        if len(vals) != 4:\n",
        "                            continue\n",
        "                        xmin, ymin, xmax, ymax = vals\n",
        "                        yolo_vals = convert_to_yolo_format(xmin, ymin, xmax, ymax, w, h)\n",
        "                        yolo_lines.append(\" \".join(map(str, yolo_vals)))\n",
        "\n",
        "            out_label_path = os.path.join(out_label_dir, new_img_name.rsplit(\".\", 1)[0] + \".txt\")\n",
        "            with open(out_label_path, \"w\") as f:\n",
        "                f.write(\"\\n\".join(yolo_lines))"
      ],
      "metadata": {
        "id": "zde6mzw4etdu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#path of dataset\n",
        "path_name='/content/dataset'\n",
        "process_split(path_name,'val')"
      ],
      "metadata": {
        "id": "anQz-aJ0ewn4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"lung_tumor.yaml\", \"w\") as f:\n",
        "    f.write(f\"\"\"train: {os.path.join(path_name, 'images', \"train\")}\n",
        "val: {os.path.join(path_name, 'images', \"val\")}\n",
        "nc: 1\n",
        "names: ['tumor']\n",
        "\"\"\")"
      ],
      "metadata": {
        "id": "TzVjxN_rif7x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#path of model\n",
        "model = YOLO('/content/best(2).pt')\n",
        "metrics = model.val(data='lung_tumor.yaml', split='val')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5AKKA6objkdu",
        "outputId": "7bc5197e-527e-426d-b996-e6f97f87dac9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.143 🚀 Python-3.11.12 torch-2.6.0+cu124 CPU (Intel Xeon 2.20GHz)\n",
            "Model summary (fused): 72 layers, 3,005,843 parameters, 0 gradients, 8.1 GFLOPs\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 1132.3±277.1 MB/s, size: 34.7 KB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/dataset/labels/val.cache... 98 images, 20 backgrounds, 0 corrupt: 100%|██████████| 98/98 [00:00<?, ?it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [01:30<00:00, 12.97s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         98         86      0.873      0.605      0.688      0.389\n",
            "Speed: 20.7ms preprocess, 884.3ms inference, 0.0ms loss, 1.3ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/val6\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"loss: {metrics.speed['loss']}\")\n",
        "print(f\"mAP@0.5: {metrics.box.map50:.4f}\")\n",
        "print(f\"mAP@0.5:0.95: {metrics.box.map:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tKTYD6nJjlZh",
        "outputId": "8b5f1dbf-4b4b-4f1f-afcd-28214c8eeff4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss: 0.00014389795013608372\n",
            "mAP@0.5: 0.6883\n",
            "mAP@0.5:0.95: 0.3887\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Validation on detected images (2 stages modelling)**"
      ],
      "metadata": {
        "id": "DZKQGXv7QUs3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO"
      ],
      "metadata": {
        "id": "7GvQHDAcUOfJ"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def segment_detections(val_dataset, detection_model, conf=0.3):\n",
        "\n",
        "\n",
        "    # Loop through each image in the validation dataset\n",
        "    for img_path, image, _ in val_dataset:\n",
        "\n",
        "      # Get the ground truth bounding box for that image\n",
        "      ground_truth_boxes_path = img_path.replace('images', 'detections').replace('.png', '.txt')\n",
        "\n",
        "      # See if detections exist\n",
        "      try:\n",
        "        with open(ground_truth_boxes_path, 'r') as file:\n",
        "            ground_truth_boxes = file.read().splitlines()\n",
        "      except:\n",
        "        continue\n",
        "\n",
        "      # Get Segmentation masks\n",
        "      ground_truth_segmentation_images = img_path.replace('images', 'masks')\n",
        "\n",
        "      results = detection_model(img_path, conf=conf)\n",
        "\n",
        "      # Get the predicted bounding boxes\n",
        "      boxes = results[0].boxes\n",
        "      scores = results[0].boxes.conf.cpu().numpy()\n",
        "\n",
        "      image = cv2.imread(img_path)\n",
        "\n",
        "      for box in boxes:\n",
        "          x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
        "          conf = box.conf[0].item()\n",
        "          label = box.cls[0].item()\n",
        "          cv2.rectangle(image, (x1, y1), (x2, y2), (0,255,0), 2)\n",
        "          cv2.putText(image, f\"Tumor {conf:.2f}\", (x1, y1 - 5),\n",
        "                      cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,255,0), 1)"
      ],
      "metadata": {
        "id": "j33X-hFigV9O"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "detection_model = YOLO('/content/best(2).pt')"
      ],
      "metadata": {
        "id": "EIxRbUbJUDt2"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "segment_detections(val_dataset, detection_model)"
      ],
      "metadata": {
        "id": "8-AJ3EH3T7cJ",
        "outputId": "641aeb49-3fc7-4ce6-e121-b12f836e67a0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/drive/MyDrive/LungTumorDetectionAndSegmentation/val/images/Subject_59/90.png: 1024x1024 (no detections), 597.6ms\n",
            "Speed: 10.5ms preprocess, 597.6ms inference, 1.0ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/LungTumorDetectionAndSegmentation/val/images/Subject_59/88.png: 1024x1024 1 tumor, 610.9ms\n",
            "Speed: 9.2ms preprocess, 610.9ms inference, 1.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/LungTumorDetectionAndSegmentation/val/images/Subject_59/84.png: 1024x1024 1 tumor, 616.0ms\n",
            "Speed: 9.0ms preprocess, 616.0ms inference, 1.5ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/LungTumorDetectionAndSegmentation/val/images/Subject_59/82.png: 1024x1024 1 tumor, 598.6ms\n",
            "Speed: 9.3ms preprocess, 598.6ms inference, 1.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/LungTumorDetectionAndSegmentation/val/images/Subject_59/79.png: 1024x1024 (no detections), 628.6ms\n",
            "Speed: 8.6ms preprocess, 628.6ms inference, 0.9ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/LungTumorDetectionAndSegmentation/val/images/Subject_59/77.png: 1024x1024 (no detections), 618.8ms\n",
            "Speed: 9.9ms preprocess, 618.8ms inference, 1.1ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/LungTumorDetectionAndSegmentation/val/images/Subject_59/80.png: 1024x1024 (no detections), 584.2ms\n",
            "Speed: 9.4ms preprocess, 584.2ms inference, 0.9ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/LungTumorDetectionAndSegmentation/val/images/Subject_59/76.png: 1024x1024 (no detections), 587.9ms\n",
            "Speed: 9.0ms preprocess, 587.9ms inference, 0.9ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/LungTumorDetectionAndSegmentation/val/images/Subject_59/83.png: 1024x1024 1 tumor, 639.7ms\n",
            "Speed: 8.6ms preprocess, 639.7ms inference, 1.3ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/LungTumorDetectionAndSegmentation/val/images/Subject_59/87.png: 1024x1024 1 tumor, 577.7ms\n",
            "Speed: 8.7ms preprocess, 577.7ms inference, 1.9ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/LungTumorDetectionAndSegmentation/val/images/Subject_59/78.png: 1024x1024 (no detections), 855.3ms\n",
            "Speed: 9.3ms preprocess, 855.3ms inference, 1.2ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/LungTumorDetectionAndSegmentation/val/images/Subject_59/89.png: 1024x1024 (no detections), 868.3ms\n",
            "Speed: 18.4ms preprocess, 868.3ms inference, 1.3ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/LungTumorDetectionAndSegmentation/val/images/Subject_59/86.png: 1024x1024 (no detections), 1170.6ms\n",
            "Speed: 19.0ms preprocess, 1170.6ms inference, 1.1ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/LungTumorDetectionAndSegmentation/val/images/Subject_59/81.png: 1024x1024 (no detections), 897.3ms\n",
            "Speed: 31.5ms preprocess, 897.3ms inference, 1.3ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/LungTumorDetectionAndSegmentation/val/images/Subject_59/85.png: 1024x1024 (no detections), 705.2ms\n",
            "Speed: 11.1ms preprocess, 705.2ms inference, 4.9ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/LungTumorDetectionAndSegmentation/val/images/Subject_59/75.png: 1024x1024 (no detections), 642.0ms\n",
            "Speed: 10.1ms preprocess, 642.0ms inference, 0.9ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/LungTumorDetectionAndSegmentation/val/images/Subject_57/214.png: 1024x1024 (no detections), 699.8ms\n",
            "Speed: 10.1ms preprocess, 699.8ms inference, 0.9ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/LungTumorDetectionAndSegmentation/val/images/Subject_57/202.png: 1024x1024 (no detections), 672.6ms\n",
            "Speed: 11.4ms preprocess, 672.6ms inference, 0.9ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/LungTumorDetectionAndSegmentation/val/images/Subject_57/218.png: 1024x1024 (no detections), 892.2ms\n",
            "Speed: 13.1ms preprocess, 892.2ms inference, 0.9ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/LungTumorDetectionAndSegmentation/val/images/Subject_57/209.png: 1024x1024 1 tumor, 784.8ms\n",
            "Speed: 9.8ms preprocess, 784.8ms inference, 2.0ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/LungTumorDetectionAndSegmentation/val/images/Subject_57/208.png: 1024x1024 1 tumor, 604.7ms\n",
            "Speed: 9.2ms preprocess, 604.7ms inference, 2.0ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/LungTumorDetectionAndSegmentation/val/images/Subject_57/210.png: 1024x1024 (no detections), 619.2ms\n",
            "Speed: 9.1ms preprocess, 619.2ms inference, 1.0ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/LungTumorDetectionAndSegmentation/val/images/Subject_57/201.png: 1024x1024 (no detections), 599.7ms\n",
            "Speed: 9.3ms preprocess, 599.7ms inference, 1.0ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/LungTumorDetectionAndSegmentation/val/images/Subject_57/217.png: 1024x1024 (no detections), 605.6ms\n",
            "Speed: 10.6ms preprocess, 605.6ms inference, 1.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/LungTumorDetectionAndSegmentation/val/images/Subject_57/213.png: 1024x1024 (no detections), 912.2ms\n",
            "Speed: 16.9ms preprocess, 912.2ms inference, 4.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/LungTumorDetectionAndSegmentation/val/images/Subject_57/203.png: 1024x1024 (no detections), 927.2ms\n",
            "Speed: 17.6ms preprocess, 927.2ms inference, 1.6ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/LungTumorDetectionAndSegmentation/val/images/Subject_57/211.png: 1024x1024 (no detections), 958.5ms\n",
            "Speed: 16.9ms preprocess, 958.5ms inference, 1.5ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/LungTumorDetectionAndSegmentation/val/images/Subject_57/204.png: 1024x1024 (no detections), 638.3ms\n",
            "Speed: 9.6ms preprocess, 638.3ms inference, 1.3ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/LungTumorDetectionAndSegmentation/val/images/Subject_57/207.png: 1024x1024 (no detections), 644.9ms\n",
            "Speed: 16.9ms preprocess, 644.9ms inference, 1.3ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/LungTumorDetectionAndSegmentation/val/images/Subject_57/212.png: 1024x1024 (no detections), 652.6ms\n",
            "Speed: 9.7ms preprocess, 652.6ms inference, 0.9ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/LungTumorDetectionAndSegmentation/val/images/Subject_57/216.png: 1024x1024 (no detections), 603.1ms\n",
            "Speed: 11.4ms preprocess, 603.1ms inference, 1.2ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/LungTumorDetectionAndSegmentation/val/images/Subject_57/215.png: 1024x1024 (no detections), 617.8ms\n",
            "Speed: 9.8ms preprocess, 617.8ms inference, 1.0ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/LungTumorDetectionAndSegmentation/val/images/Subject_57/205.png: 1024x1024 (no detections), 608.3ms\n",
            "Speed: 8.5ms preprocess, 608.3ms inference, 1.0ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/LungTumorDetectionAndSegmentation/val/images/Subject_57/206.png: 1024x1024 (no detections), 676.1ms\n",
            "Speed: 9.8ms preprocess, 676.1ms inference, 1.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/LungTumorDetectionAndSegmentation/val/images/Subject_58/290.png: 1024x1024 (no detections), 1124.5ms\n",
            "Speed: 11.3ms preprocess, 1124.5ms inference, 1.2ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/LungTumorDetectionAndSegmentation/val/images/Subject_58/282.png: 1024x1024 (no detections), 1355.9ms\n",
            "Speed: 8.4ms preprocess, 1355.9ms inference, 1.8ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/LungTumorDetectionAndSegmentation/val/images/Subject_58/269.png: 1024x1024 (no detections), 1237.1ms\n",
            "Speed: 12.0ms preprocess, 1237.1ms inference, 8.3ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/LungTumorDetectionAndSegmentation/val/images/Subject_58/289.png: 1024x1024 (no detections), 1173.0ms\n",
            "Speed: 11.8ms preprocess, 1173.0ms inference, 1.2ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/LungTumorDetectionAndSegmentation/val/images/Subject_58/273.png: 1024x1024 (no detections), 1046.3ms\n",
            "Speed: 29.7ms preprocess, 1046.3ms inference, 1.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/LungTumorDetectionAndSegmentation/val/images/Subject_58/278.png: 1024x1024 (no detections), 604.6ms\n",
            "Speed: 13.9ms preprocess, 604.6ms inference, 1.0ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/LungTumorDetectionAndSegmentation/val/images/Subject_58/280.png: 1024x1024 (no detections), 592.6ms\n",
            "Speed: 8.2ms preprocess, 592.6ms inference, 0.9ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/LungTumorDetectionAndSegmentation/val/images/Subject_58/276.png: 1024x1024 (no detections), 629.6ms\n",
            "Speed: 9.6ms preprocess, 629.6ms inference, 0.9ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/LungTumorDetectionAndSegmentation/val/images/Subject_58/274.png: 1024x1024 (no detections), 953.1ms\n",
            "Speed: 28.6ms preprocess, 953.1ms inference, 1.0ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/LungTumorDetectionAndSegmentation/val/images/Subject_58/270.png: 1024x1024 (no detections), 778.1ms\n",
            "Speed: 9.2ms preprocess, 778.1ms inference, 0.9ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/LungTumorDetectionAndSegmentation/val/images/Subject_58/275.png: 1024x1024 (no detections), 590.6ms\n",
            "Speed: 10.0ms preprocess, 590.6ms inference, 0.9ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/LungTumorDetectionAndSegmentation/val/images/Subject_58/271.png: 1024x1024 (no detections), 639.8ms\n",
            "Speed: 9.2ms preprocess, 639.8ms inference, 1.2ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/LungTumorDetectionAndSegmentation/val/images/Subject_58/283.png: 1024x1024 (no detections), 679.0ms\n",
            "Speed: 12.1ms preprocess, 679.0ms inference, 1.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/LungTumorDetectionAndSegmentation/val/images/Subject_58/284.png: 1024x1024 1 tumor, 565.0ms\n",
            "Speed: 9.2ms preprocess, 565.0ms inference, 1.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/LungTumorDetectionAndSegmentation/val/images/Subject_58/272.png: 1024x1024 (no detections), 610.1ms\n",
            "Speed: 8.7ms preprocess, 610.1ms inference, 1.0ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/LungTumorDetectionAndSegmentation/val/images/Subject_58/287.png: 1024x1024 1 tumor, 953.1ms\n",
            "Speed: 11.2ms preprocess, 953.1ms inference, 4.3ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/LungTumorDetectionAndSegmentation/val/images/Subject_58/288.png: 1024x1024 (no detections), 907.0ms\n",
            "Speed: 15.6ms preprocess, 907.0ms inference, 1.2ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/LungTumorDetectionAndSegmentation/val/images/Subject_58/285.png: 1024x1024 (no detections), 907.8ms\n",
            "Speed: 14.8ms preprocess, 907.8ms inference, 1.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/LungTumorDetectionAndSegmentation/val/images/Subject_58/277.png: 1024x1024 (no detections), 614.6ms\n",
            "Speed: 11.8ms preprocess, 614.6ms inference, 1.2ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/LungTumorDetectionAndSegmentation/val/images/Subject_58/279.png: 1024x1024 (no detections), 623.8ms\n",
            "Speed: 8.6ms preprocess, 623.8ms inference, 0.9ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/LungTumorDetectionAndSegmentation/val/images/Subject_58/281.png: 1024x1024 (no detections), 616.0ms\n",
            "Speed: 8.2ms preprocess, 616.0ms inference, 0.9ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/LungTumorDetectionAndSegmentation/val/images/Subject_58/286.png: 1024x1024 (no detections), 650.9ms\n",
            "Speed: 8.7ms preprocess, 650.9ms inference, 1.0ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/LungTumorDetectionAndSegmentation/val/images/Subject_58/294.png: 1024x1024 (no detections), 657.7ms\n",
            "Speed: 9.1ms preprocess, 657.7ms inference, 0.9ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/LungTumorDetectionAndSegmentation/val/images/Subject_58/299.png: 1024x1024 (no detections), 586.9ms\n",
            "Speed: 8.8ms preprocess, 586.9ms inference, 0.9ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/LungTumorDetectionAndSegmentation/val/images/Subject_58/297.png: 1024x1024 (no detections), 591.0ms\n",
            "Speed: 11.9ms preprocess, 591.0ms inference, 0.9ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/LungTumorDetectionAndSegmentation/val/images/Subject_58/303.png: 1024x1024 (no detections), 630.4ms\n",
            "Speed: 9.4ms preprocess, 630.4ms inference, 1.0ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/LungTumorDetectionAndSegmentation/val/images/Subject_58/301.png: 1024x1024 (no detections), 609.6ms\n",
            "Speed: 13.9ms preprocess, 609.6ms inference, 0.9ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/LungTumorDetectionAndSegmentation/val/images/Subject_58/292.png: 1024x1024 (no detections), 616.0ms\n",
            "Speed: 8.3ms preprocess, 616.0ms inference, 1.1ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/LungTumorDetectionAndSegmentation/val/images/Subject_58/295.png: 1024x1024 (no detections), 608.7ms\n",
            "Speed: 8.9ms preprocess, 608.7ms inference, 0.9ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/LungTumorDetectionAndSegmentation/val/images/Subject_58/293.png: 1024x1024 (no detections), 785.7ms\n",
            "Speed: 9.7ms preprocess, 785.7ms inference, 1.8ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/LungTumorDetectionAndSegmentation/val/images/Subject_58/298.png: 1024x1024 (no detections), 909.0ms\n",
            "Speed: 14.0ms preprocess, 909.0ms inference, 1.7ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/LungTumorDetectionAndSegmentation/val/images/Subject_58/296.png: 1024x1024 (no detections), 1019.4ms\n",
            "Speed: 15.5ms preprocess, 1019.4ms inference, 1.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/LungTumorDetectionAndSegmentation/val/images/Subject_58/300.png: 1024x1024 (no detections), 854.7ms\n",
            "Speed: 15.2ms preprocess, 854.7ms inference, 1.0ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/LungTumorDetectionAndSegmentation/val/images/Subject_58/302.png: 1024x1024 (no detections), 682.9ms\n",
            "Speed: 8.8ms preprocess, 682.9ms inference, 0.9ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/LungTumorDetectionAndSegmentation/val/images/Subject_58/291.png: 1024x1024 (no detections), 595.1ms\n",
            "Speed: 9.8ms preprocess, 595.1ms inference, 1.3ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/LungTumorDetectionAndSegmentation/val/images/Subject_60/53.png: 1024x1024 (no detections), 632.6ms\n",
            "Speed: 8.3ms preprocess, 632.6ms inference, 0.9ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/LungTumorDetectionAndSegmentation/val/images/Subject_60/49.png: 1024x1024 (no detections), 619.5ms\n",
            "Speed: 9.3ms preprocess, 619.5ms inference, 0.9ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/LungTumorDetectionAndSegmentation/val/images/Subject_60/48.png: 1024x1024 (no detections), 612.5ms\n",
            "Speed: 9.8ms preprocess, 612.5ms inference, 0.9ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/LungTumorDetectionAndSegmentation/val/images/Subject_60/51.png: 1024x1024 (no detections), 612.1ms\n",
            "Speed: 10.2ms preprocess, 612.1ms inference, 1.2ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/LungTumorDetectionAndSegmentation/val/images/Subject_60/54.png: 1024x1024 (no detections), 855.2ms\n",
            "Speed: 34.2ms preprocess, 855.2ms inference, 0.9ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/LungTumorDetectionAndSegmentation/val/images/Subject_60/46.png: 1024x1024 (no detections), 600.2ms\n",
            "Speed: 10.5ms preprocess, 600.2ms inference, 0.9ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/LungTumorDetectionAndSegmentation/val/images/Subject_60/47.png: 1024x1024 (no detections), 607.3ms\n",
            "Speed: 9.4ms preprocess, 607.3ms inference, 1.0ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/LungTumorDetectionAndSegmentation/val/images/Subject_60/52.png: 1024x1024 (no detections), 615.2ms\n",
            "Speed: 9.6ms preprocess, 615.2ms inference, 0.9ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/LungTumorDetectionAndSegmentation/val/images/Subject_60/50.png: 1024x1024 (no detections), 767.0ms\n",
            "Speed: 8.3ms preprocess, 767.0ms inference, 1.2ms postprocess per image at shape (1, 3, 1024, 1024)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nKQyCX6qUPQh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}